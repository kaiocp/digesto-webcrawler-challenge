# digesto-webcrawler-challenge

Este projeto corresponde a uma etapa para o processo seletivo para estagiáiro na Jusbrasil. O objetivo era desenvolver dois crawlers para as seguintes páginas-alvo:

1. https://www.vultr.com/products/cloud-compute/#pricing (apenas SSDCloud
Instances)
2. https://www.digitalocean.com/pricing/ (apenas tabela Basic droplets)

O crawler deveria ainda ter as funcionalidades de imprimir na tela (--print), salvar como .csv (--save_csv) e salvar como .json (--save_json).

## Começando

Para executar o projeto é preciso ter o Python 3 instalado. Além disso, é necessário instalar os módulos utilizados utilizando o comando ```pip install -r requirements.txt```

## Execução

Clone o repositório em um diretório de sua preferência e então ```git clone https://github.com/kaiocp/digesto-webcrawler-challenge```

Para executar o programa ```python3 main.py```

